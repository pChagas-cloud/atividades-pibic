{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03d322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1752447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6d6b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cifar100 dataset\n",
    "\n",
    "(A_train, b_train), (A_test, b_test) = datasets.cifar10.load_data()\n",
    "A_train = A_train/255\n",
    "A_test = A_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ef2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "#First Convolution Layer\n",
    "#Learning a total of 64 filters , which is then downsampled by maxpooling layer (2x2)\n",
    "#kernel_size 3x3 : specifying height and width of 2D convolution window\n",
    "#padding same: spatial dimensions such that: output value size matches the input volume size\n",
    "#Relu: activation function used\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(28, 28, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Second Convolution Layer\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=(28, 28, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Third Convolution Layer\n",
    "model.add(Conv2D(256, (3, 3), padding='same', input_shape=(28, 28, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Batch normalization  allows every layer of the network to do learning more independently. It is used to normalize the output of the previous layers.\n",
    "#Flattening : converting 2d array into single long continuous vector\n",
    "#Dropouts used to avoid overfitting\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Dense layers produce the output = activation(dot(input, kernel) + bias)\n",
    "#Used to predict labels\n",
    "#Softmax activation function used for output labels\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f63b1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b9320d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.1043 - accuracy: 0.9674\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 72s 39ms/step - loss: 0.0469 - accuracy: 0.9858\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0360 - accuracy: 0.9894\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0205 - accuracy: 0.9936\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0201 - accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0173 - accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0156 - accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0145 - accuracy: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f07402fbb20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST-DATASET TRAINING\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5155c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0401 - accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04007489234209061, 0.989300012588501]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST-DATASET TESTING\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
